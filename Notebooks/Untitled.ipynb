{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Models implementation\n",
    "\n",
    "#### In order to implement the models, we have at first to select features.\n",
    "\n",
    "### V.1 Feature selection\n",
    "\n",
    "#### We remove any feature that might not help to get better scores. Actually, any feature that is redundant or isn't correlated with the selected label might lead to an overfitting or increase the variance in our calculation. Therefore, those feature should be removed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even if the hot encoding method, which consists in constructing as many variables as the number of unique categories in this variable, improves the F1-score for the random forest by a few tenths, the label encoding approach, which consists in simply converting each value of this column into an integer, is preferred here in order not to degrade too much the results obtained with the other methods and to propose a relevant comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_processed_total\n",
    "\n",
    "df_model['code_commune'] = df_model['code_commune'].astype(str)\n",
    "df_model['id_mutation'] = df_model['id_mutation'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df_model.code_commune=le.fit_transform(df_model.code_commune)\n",
    "df_model.id_mutation=le.fit_transform(df_model.id_mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing to correlation among the columns of the data\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.heatmap(df_model.corr(), annot=True,cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap describe how much each two variables are corralated.Max correlation is for identical two columns which will give a correlation factor of 1. This is why, for example the diagaonale is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(['date_mutation', 'Month', 'nombre_lots'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
